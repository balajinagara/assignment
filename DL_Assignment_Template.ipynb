{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balajinagara/assignment/blob/main/DL_Assignment_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bda93ba",
      "metadata": {
        "id": "9bda93ba"
      },
      "source": [
        "## Group No : 108\n",
        "\n",
        "## Group Member Names:\n",
        "1.\n",
        "2.\n",
        "3.\n",
        "4."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bec56339",
      "metadata": {
        "id": "bec56339"
      },
      "source": [
        "# 1. Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "46631608",
      "metadata": {
        "id": "46631608"
      },
      "outputs": [],
      "source": [
        "##---------Type the code below this line------------------##\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Acquisition  -- Score: 0.5 Mark\n",
        "\n",
        "For the problem identified by you, students have to find the data source themselves from any data source.\n",
        "\n"
      ],
      "metadata": {
        "id": "M26PTVYhTLyo"
      },
      "id": "M26PTVYhTLyo"
    },
    {
      "cell_type": "code",
      "source": [
        "##---------Type the code below this line------------------##\n",
        "# Load the tf_flowers dataset\n",
        "dataset_name = 'tf_flowers'\n",
        "data_dir = '/content/dataset/tf_flowers'  # Specify the directory to save the dataset\n",
        "tfds.load(dataset_name, data_dir=data_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyDM82iOTS7F",
        "outputId": "e299bdae-dc85-49d9-b8aa-25b213b636e3"
      },
      "id": "zyDM82iOTS7F",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <_PrefetchDataset element_spec={'image': TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cc8e0cb",
      "metadata": {
        "id": "3cc8e0cb"
      },
      "source": [
        "\n",
        "## 2.1 Code for converting the above downloaded data into a form suitable for DL\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "812edb18",
      "metadata": {
        "id": "812edb18"
      },
      "source": [
        "## 2.1 Write your observations from the above.\n",
        "\n",
        "1. Size of the dataset\n",
        "2. What type of data attributes are there?\n",
        "3. What are you classifying?\n",
        "4. Plot the distribution of the categories of the target / label.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4b51d895",
      "metadata": {
        "id": "4b51d895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7a20503d-2818-46c3-a3da-dcdce1a9365f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the tf_flowers dataset: 3670\n",
            "tfds.core.DatasetInfo(\n",
            "    name='tf_flowers',\n",
            "    full_name='tf_flowers/3.0.1',\n",
            "    description=\"\"\"\n",
            "    A large set of images of flowers\n",
            "    \"\"\",\n",
            "    homepage='https://www.tensorflow.org/tutorials/load_data/images',\n",
            "    data_path=PosixGPath('/tmp/tmphmn6bu80tfds'),\n",
            "    file_format=tfrecord,\n",
            "    download_size=218.21 MiB,\n",
            "    dataset_size=221.83 MiB,\n",
            "    features=FeaturesDict({\n",
            "        'image': Image(shape=(None, None, 3), dtype=uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=int64, num_classes=5),\n",
            "    }),\n",
            "    supervised_keys=('image', 'label'),\n",
            "    disable_shuffling=False,\n",
            "    splits={\n",
            "        'train': <SplitInfo num_examples=3670, num_shards=2>,\n",
            "    },\n",
            "    citation=\"\"\"@ONLINE {tfflowers,\n",
            "    author = \"The TensorFlow Team\",\n",
            "    title = \"Flowers\",\n",
            "    month = \"jan\",\n",
            "    year = \"2019\",\n",
            "    url = \"http://download.tensorflow.org/example_images/flower_photos.tgz\" }\"\"\",\n",
            ")\n",
            "Number of classes: 5\n",
            "Class names: ['dandelion', 'daisy', 'tulips', 'sunflowers', 'roses']\n",
            "Splits: dict_keys(['train'])\n",
            "The tf_flowers dataset is classifying the following classes:\n",
            "dandelion\n",
            "daisy\n",
            "tulips\n",
            "sunflowers\n",
            "roses\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAH3CAYAAABdFJ4JAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABYW0lEQVR4nO3dd1gUV9sG8HvpqBQriCJgDSiKCiL2gmLBEjXGElsU1NhN7N1EjSb2rlGxJtaIsWDvEkTsBlBjL0AiCqJ0nu8PP+Z1gxWRhfH+XddeyZ45O/vMuOXmzJlZjYgIiIiIiFRKT9cFEBEREX1MDDtERESkagw7REREpGoMO0RERKRqDDtERESkagw7REREpGoMO0RERKRqDDtERESkagw7REREpGoMO/TJmjhxIjQaTbY8V7169VCvXj3l/pEjR6DRaLBly5Zsef7u3bvD3t4+W54rs+Li4tCrVy9YW1tDo9Fg8ODBH7Q+Pz8/aDQa3Lp1K0vqI9377/uI6F0x7JAqpH+xpd9MTExgY2MDLy8vzJs3D0+fPs2S53nw4AEmTpyI8+fPZ8n6slJOru1dTJ06FX5+fujbty/Wrl2LLl26vLavvb291r/3y7eEhIRsrDp7HTlyBG3atIG1tTWMjIxQpEgRtGjRAtu2bXvvdT1//hwTJ07EkSNHsr5QohzGQNcFEGWlyZMnw8HBAcnJyYiIiMCRI0cwePBgzJo1Czt27EDFihWVvmPHjsXIkSPfa/0PHjzApEmTYG9vDxcXl3d+3L59+97reTLjTbUtX74caWlpH72GD3Ho0CFUr14dEyZMeKf+Li4u+PbbbzO0GxkZZXVpOcKECRMwefJklClTBr1794adnR0ePXqE3bt3o23btli/fj06der0zut7/vw5Jk2aBAC5ZrQkO95HpE4MO6QqTZs2haurq3J/1KhROHToELy9vdGyZUuEhobC1NQUAGBgYAADg4/7Fnj+/Dny5Mmj8y9gQ0NDnT7/u4iKioKTk9M79y9WrBi++uqrj1hR9hERJCQkKK/N/9qyZQsmT56Mdu3aYcOGDVr/nsOGDcPevXuRnJycXeVmu5zyPqLci4exSPUaNGiAcePG4fbt21i3bp3S/qo5O/v370etWrVgaWmJfPnyoVy5chg9ejSAF4cQ3NzcAAA9evRQDpv4+fkBePHXcYUKFRASEoI6deogT548ymNfN9cgNTUVo0ePhrW1NfLmzYuWLVvi7t27Wn3s7e3RvXv3DI99eZ1vq+1Vc3aePXuGb7/9Fra2tjA2Nka5cuXw888/Q0S0+mk0GvTv3x/bt29HhQoVYGxsjPLlyyMgIODVO/w/oqKi0LNnT1hZWcHExASVKlXC6tWrleXp85du3ryJXbt2KbV/rLk2ixYtQvny5WFsbAwbGxv069cPT548UZbPmzcP+vr6Wm0zZ86ERqPB0KFDlbbU1FSYmZlhxIgRSltaWhrmzJmD8uXLw8TEBFZWVujduzceP36sVYO9vT28vb2xd+9euLq6wtTUFEuXLn1tzePGjUOBAgWwcuXKVwZXLy8veHt7AwCSkpIwfvx4VK1aFRYWFsibNy9q166Nw4cPK/1v3bqFwoULAwAmTZqk7POJEycqfcLCwtCuXTsUKFAAJiYmcHV1xY4dOzI898WLF1G3bl2YmpqiePHi+OGHH7Bq1apX/hu+bd8D7/8+SkxMxIQJE1C6dGkYGxvD1tYWw4cPR2Jiola/N723Sf04skOfhC5dumD06NHYt28ffHx8XtnnypUr8Pb2RsWKFTF58mQYGxvj+vXrOHnyJADA0dERkydPxvjx4+Hr64vatWsDAGrUqKGs49GjR2jatCk6dOiAr776ClZWVm+sa8qUKdBoNBgxYgSioqIwZ84ceHp64vz586/9K/9V3qW2l4kIWrZsicOHD6Nnz55wcXHB3r17MWzYMNy/fx+zZ8/W6n/ixAls27YN33zzDczMzDBv3jy0bdsWd+7cQcGCBV9bV3x8POrVq4fr16+jf//+cHBwwObNm9G9e3c8efIEgwYNgqOjI9auXYshQ4agePHiyqGp9C/j10lOTsa///6r1ZYnTx7kyZPntY+ZOHEiJk2aBE9PT/Tt2xfh4eFYvHgxgoODcfLkSRgaGqJ27dpIS0vDiRMnlABx/Phx6Onp4fjx48q6zp07h7i4ONSpU0dp6927N/z8/NCjRw8MHDgQN2/exIIFC3Du3Dll/enCw8PRsWNH9O7dGz4+PihXrtwra7527RrCwsLw9ddfw8zM7I37BABiY2Pxyy+/oGPHjvDx8cHTp0+xYsUKeHl54fTp03BxcUHhwoWxePFi9O3bF59//jnatGkDAMph3itXrqBmzZooVqwYRo4cibx582LTpk1o3bo1tm7dis8//xwAcP/+fdSvXx8ajQajRo1C3rx58csvv8DY2DhT+z7du76P0tLS0LJlS5w4cQK+vr5wdHTEpUuXMHv2bFy9ehXbt29XtudN7236BAiRCqxatUoASHBw8Gv7WFhYSOXKlZX7EyZMkJffArNnzxYA8s8//7x2HcHBwQJAVq1alWFZ3bp1BYAsWbLklcvq1q2r3D98+LAAkGLFiklsbKzSvmnTJgEgc+fOVdrs7OykW7dub13nm2rr1q2b2NnZKfe3b98uAOSHH37Q6teuXTvRaDRy/fp1pQ2AGBkZabVduHBBAMj8+fMzPNfL5syZIwBk3bp1SltSUpJ4eHhIvnz5tLbdzs5Omjdv/sb1vdwXQIbbhAkTlD7pr4mbN2+KiEhUVJQYGRlJ48aNJTU1Vem3YMECASArV64UEZHU1FQxNzeX4cOHi4hIWlqaFCxYUL744gvR19eXp0+fiojIrFmzRE9PTx4/fiwiIsePHxcAsn79eq1aAwICMrSn1x8QEPDWbfX39xcAMnv27HfaNykpKZKYmKjV9vjxY7GyspKvv/5aafvnn38y7LN0DRs2FGdnZ0lISFDa0tLSpEaNGlKmTBmlbcCAAaLRaOTcuXNK26NHj6RAgQKZ2vci7/c+Wrt2rejp6cnx48e1+i1ZskQAyMmTJ0Xk3d7bpG48jEWfjHz58r3xrCxLS0sAgL+/f6Yn8xobG6NHjx7v3L9r165af623a9cORYsWxe7duzP1/O9q9+7d0NfXx8CBA7Xav/32W4gI9uzZo9Xu6emJUqVKKfcrVqwIc3Nz3Lhx463PY21tjY4dOypthoaGGDhwIOLi4nD06NFMb4O7uzv279+vdevatetr+x84cABJSUkYPHgw9PT+99Hn4+MDc3Nz7Nq1CwCgp6eHGjVq4NixYwCA0NBQPHr0CCNHjoSIIDAwEMCL0Z4KFSoor5vNmzfDwsICjRo1wr///qvcqlatinz58mkdRgIABwcHeHl5vXU7Y2NjAeCdRnUAQF9fX5nbkpaWhujoaKSkpMDV1RVnz5596+Ojo6Nx6NAhtG/fHk+fPlW249GjR/Dy8sK1a9dw//59AEBAQAA8PDy0JsQXKFAAnTt31lrnu+77dO/6Ptq8eTMcHR3x2Wefae3zBg0aAICyz7PivU25G8MOfTLi4uLe+IXx5ZdfombNmujVqxesrKzQoUMHbNq06b0+HIsVK/ZekyjLlCmjdV+j0aB06dIf/dowt2/fho2NTYb94ejoqCx/WYkSJTKsI3/+/BnmorzqecqUKaP1Bfem53kfhQoVgqenp9atZMmSb6wFQIbDRUZGRihZsqRWLbVr10ZISAji4+Nx/PhxFC1aFFWqVEGlSpWUQ1knTpxQDhcCLw43xcTEoEiRIihcuLDWLS4uDlFRUVrP6+Dg8E7baW5uDgDvdfmE1atXo2LFijAxMUHBggVRuHBh7Nq1CzExMW997PXr1yEiGDduXIbtSD9TLn1bbt++jdKlS2dYx3/b3mffA+/+Prp27RquXLmSoc6yZctq1ZkV723K3Thnhz4J9+7dQ0xMzCs/mNOZmpri2LFjOHz4MHbt2oWAgABs3LgRDRo0wL59+6Cvr//W53mfeTbv6nUXPkxNTX2nmrLC655H/jOZWS1q1aqF5ORkBAYG4vjx40qoqV27No4fP46wsDD8888/WmEnLS0NRYoUwfr161+5zv/OQXrX18pnn30GALh06dI79V+3bh26d++O1q1bY9iwYShSpAj09fUxbdo0/P333299fHoA+O6771478vSm91FWeNd9k5aWBmdnZ8yaNeuVy21tbZX1feh7m3I3hh36JKxduxYA3nrYQE9PDw0bNkTDhg0xa9YsTJ06FWPGjMHhw4fh6emZ5VdcvnbtmtZ9EcH169e1rgeUP3/+DGesAC/+Wn55JON9arOzs8OBAwfw9OlTrdGdsLAwZXlWsLOzw8WLF5GWlqY1upPVz/OutQAvJga/vN+SkpJw8+ZNeHp6Km3VqlWDkZERjh8/juPHj2PYsGEAgDp16mD58uU4ePCgcj9dqVKlcODAAdSsWTNLQ2/ZsmVRrlw5+Pv7Y+7cuciXL98b+2/ZsgUlS5bEtm3btF4T/71+0eteL+n7xtDQUGufvIqdnR2uX7+eof2/be+z799HqVKlcOHCBTRs2PCtr/+3vbdJ3XgYi1Tv0KFD+P777+Hg4JBhLsHLoqOjM7Slz0VIP401b968APDK8JEZa9as0To8sWXLFjx8+BBNmzZV2kqVKoU///wTSUlJStvOnTsznKL+PrU1a9YMqampWLBggVb77NmzodFotJ7/QzRr1gwRERHYuHGj0paSkoL58+cjX758qFu3bpY8z7vw9PSEkZER5s2bpzUitWLFCsTExKB58+ZKm4mJCdzc3PDrr7/izp07WiM78fHxmDdvHkqVKoWiRYsqj2nfvj1SU1Px/fffZ3julJSUD3rNTJo0CY8ePUKvXr2QkpKSYfm+ffuwc+dOAP8bhXt5G4OCgpS5RunSz1r7b11FihRBvXr1sHTpUjx8+DDDc/3zzz/K/3t5eSEwMFDrqt3R0dEZRrfeZ9+/j/bt2+P+/ftYvnx5hmXx8fF49uyZUtN//fe9TerGkR1SlT179iAsLAwpKSmIjIzEoUOHsH//ftjZ2WHHjh0wMTF57WMnT56MY8eOoXnz5rCzs0NUVBQWLVqE4sWLo1atWgBeBA9LS0ssWbIEZmZmyJs3L9zd3d95/sV/FShQALVq1UKPHj0QGRmJOXPmoHTp0lqnx/fq1QtbtmxBkyZN0L59e/z9999Yt26d1oTh962tRYsWqF+/PsaMGYNbt26hUqVK2LdvH/z9/TF48OAM684sX19fLF26FN27d0dISAjs7e2xZcsWnDx5EnPmzHnnSbdZoXDhwhg1ahQmTZqEJk2aoGXLlggPD8eiRYvg5uaW4QKFtWvXxo8//ggLCws4OzsDeBEEypUrh/Dw8AzXPqpbty569+6NadOm4fz582jcuDEMDQ1x7do1bN68GXPnzkW7du0yVfuXX36JS5cuYcqUKTh37hw6duyoXEE5ICAABw8exIYNGwAA3t7e2LZtGz7//HM0b94cN2/exJIlS+Dk5IS4uDhlnaampnBycsLGjRtRtmxZFChQABUqVECFChWwcOFC1KpVC87OzvDx8UHJkiURGRmJwMBA3Lt3DxcuXAAADB8+HOvWrUOjRo0wYMAA5dTzEiVKIDo6Whlted99/666dOmCTZs2oU+fPjh8+DBq1qyJ1NRUhIWFYdOmTcp1jN7lvU0qp7sTwYiyTvppxuk3IyMjsba2lkaNGsncuXO1TnFO999Tzw8ePCitWrUSGxsbMTIyEhsbG+nYsaNcvXpV63H+/v7i5OQkBgYGWqd6161bV8qXL//K+l536vmvv/4qo0aNkiJFioipqak0b95cbt++neHxM2fOlGLFiomxsbHUrFlTzpw5k2Gdb6rtv6eei4g8ffpUhgwZIjY2NmJoaChlypSRn376SdLS0rT6AZB+/fplqOl1p8T/V2RkpPTo0UMKFSokRkZG4uzs/MrT49/31PO39f3vqefpFixYIJ999pkYGhqKlZWV9O3bVzl9/GW7du0SANK0aVOt9l69egkAWbFixSufd9myZVK1alUxNTUVMzMzcXZ2luHDh8uDBw8yta0vS3+NFilSRAwMDKRw4cLSokUL8ff3V/qkpaXJ1KlTxc7OToyNjaVy5cqyc+fOV74GTp06JVWrVhUjI6MMp6H//fff0rVrV7G2thZDQ0MpVqyYeHt7y5YtW7TWce7cOaldu7YYGxtL8eLFZdq0aTJv3jwBIBEREVp932Xfv8/7SOTFpQymT58u5cuXF2NjY8mfP79UrVpVJk2aJDExMVr77W3vbVIvjYhKZxgSEZFODB48GEuXLkVcXBwn/1KOwDk7RESUafHx8Vr3Hz16hLVr16JWrVoMOpRjcM4OERFlmoeHB+rVqwdHR0dERkZixYoViI2Nxbhx43RdGpGCYYeIiDKtWbNm2LJlC5YtWwaNRoMqVapgxYoVWqflE+ka5+wQERGRqnHODhEREakaD2PhxSXHHzx4ADMzsyy/Qi4RERF9HCKCp0+fwsbGJsNv8L2MYQfAgwcPlN9QISIiotzl7t27KF68+GuXM+wAylVc7969q/zCMBEREeVssbGxsLW1fevV2Bl28L8fxDM3N2fYISIiymXe+kOw2VQHERERkU4w7BAREZGqMewQERGRqjHsEBERkaox7BAREZGqMewQERGRqjHsEBERkaox7BAREZGqMewQERGRqjHsEBERkaox7BAREZGqMewQERGRqjHsEBERkaox7BAREZGqMewQERGRqhnougC1sx+5S9cl5Bq3fmyu6xKIiEiFOLJDREREqsawQ0RERKrGsENERESqxrBDREREqsawQ0RERKrGsENERESqxrBDREREqsawQ0RERKrGsENERESqxrBDREREqsawQ0RERKrGsENERESqxrBDREREqsawQ0RERKrGsENERESqxrBDREREqsawQ0RERKrGsENERESqxrBDREREqsawQ0RERKrGsENERESqxrBDREREqsawQ0RERKrGsENERESqxrBDREREqsawQ0RERKrGsENERESqxrBDREREqsawQ0RERKrGsENERESqxrBDREREqsawQ0RERKrGsENERESqxrBDREREqqbTsJOamopx48bBwcEBpqamKFWqFL7//nuIiNJHRDB+/HgULVoUpqam8PT0xLVr17TWEx0djc6dO8Pc3ByWlpbo2bMn4uLisntziIiIKAfSadiZPn06Fi9ejAULFiA0NBTTp0/HjBkzMH/+fKXPjBkzMG/ePCxZsgRBQUHImzcvvLy8kJCQoPTp3Lkzrly5gv3792Pnzp04duwYfH19dbFJRERElMNo5OVhlGzm7e0NKysrrFixQmlr27YtTE1NsW7dOogIbGxs8O233+K7774DAMTExMDKygp+fn7o0KEDQkND4eTkhODgYLi6ugIAAgIC0KxZM9y7dw82NjYZnjcxMRGJiYnK/djYWNja2iImJgbm5uZZuo32I3dl6frU7NaPzXVdAhER5SKxsbGwsLB46/e3Tkd2atSogYMHD+Lq1asAgAsXLuDEiRNo2rQpAODmzZuIiIiAp6en8hgLCwu4u7sjMDAQABAYGAhLS0sl6ACAp6cn9PT0EBQU9MrnnTZtGiwsLJSbra3tx9pEIiIi0jEDXT75yJEjERsbi88++wz6+vpITU3FlClT0LlzZwBAREQEAMDKykrrcVZWVsqyiIgIFClSRGu5gYEBChQooPT5r1GjRmHo0KHK/fSRHSL6MBzJfHccySTKPjoNO5s2bcL69euxYcMGlC9fHufPn8fgwYNhY2ODbt26fbTnNTY2hrGx8UdbPxEREeUcOg07w4YNw8iRI9GhQwcAgLOzM27fvo1p06ahW7dusLa2BgBERkaiaNGiyuMiIyPh4uICALC2tkZUVJTWelNSUhAdHa08noiIiD5dOp2z8/z5c+jpaZegr6+PtLQ0AICDgwOsra1x8OBBZXlsbCyCgoLg4eEBAPDw8MCTJ08QEhKi9Dl06BDS0tLg7u6eDVtBREREOZlOR3ZatGiBKVOmoESJEihfvjzOnTuHWbNm4euvvwYAaDQaDB48GD/88APKlCkDBwcHjBs3DjY2NmjdujUAwNHREU2aNIGPjw+WLFmC5ORk9O/fHx06dHjlmVhERET0adFp2Jk/fz7GjRuHb775BlFRUbCxsUHv3r0xfvx4pc/w4cPx7Nkz+Pr64smTJ6hVqxYCAgJgYmKi9Fm/fj369++Phg0bQk9PD23btsW8efN0sUlERESUw+j0Ojs5xbuep58ZPDvl3fHslNyPr/d3x9c70YfLFdfZISIiIvrYGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Qx0XQAREX0Y+5G7dF1CrnHrx+a6LoF0gCM7REREpGoMO0RERKRqDDtERESkagw7REREpGoMO0RERKRqDDtERESkagw7REREpGoMO0RERKRqDDtERESkagw7REREpGoMO0RERKRqDDtERESkagw7REREpGoMO0RERKRqDDtERESkagw7REREpGoMO0RERKRqDDtERESkagw7REREpGoMO0RERKRqDDtERESkagw7REREpGoGui6AiIgoN7IfuUvXJeQat35srtPn58gOERERqRrDDhEREakaD2ORKnF4+d3peniZiOhj48gOERERqRrDDhEREakaww4RERGpGsMOERERqRrDDhEREakaww4RERGpGsMOERERqRrDDhEREamazsPO/fv38dVXX6FgwYIwNTWFs7Mzzpw5oywXEYwfPx5FixaFqakpPD09ce3aNa11REdHo3PnzjA3N4elpSV69uyJuLi47N4UIiIiyoF0GnYeP36MmjVrwtDQEHv27MFff/2FmTNnIn/+/EqfGTNmYN68eViyZAmCgoKQN29eeHl5ISEhQenTuXNnXLlyBfv378fOnTtx7Ngx+Pr66mKTiIiIKIfR6c9FTJ8+Hba2tli1apXS5uDgoPy/iGDOnDkYO3YsWrVqBQBYs2YNrKyssH37dnTo0AGhoaEICAhAcHAwXF1dAQDz589Hs2bN8PPPP8PGxiZ7N4qIiIhyFJ2O7OzYsQOurq744osvUKRIEVSuXBnLly9Xlt+8eRMRERHw9PRU2iwsLODu7o7AwEAAQGBgICwtLZWgAwCenp7Q09NDUFDQK583MTERsbGxWjciIiJSJ52GnRs3bmDx4sUoU6YM9u7di759+2LgwIFYvXo1ACAiIgIAYGVlpfU4KysrZVlERASKFCmitdzAwAAFChRQ+vzXtGnTYGFhodxsbW2zetOIiIgoh9Bp2ElLS0OVKlUwdepUVK5cGb6+vvDx8cGSJUs+6vOOGjUKMTExyu3u3bsf9fmIiIhId3QadooWLQonJyetNkdHR9y5cwcAYG1tDQCIjIzU6hMZGakss7a2RlRUlNbylJQUREdHK33+y9jYGObm5lo3IiIiUiedhp2aNWsiPDxcq+3q1auws7MD8GKysrW1NQ4ePKgsj42NRVBQEDw8PAAAHh4eePLkCUJCQpQ+hw4dQlpaGtzd3bNhK4iIiCgn0+nZWEOGDEGNGjUwdepUtG/fHqdPn8ayZcuwbNkyAIBGo8HgwYPxww8/oEyZMnBwcMC4ceNgY2OD1q1bA3gxEtSkSRPl8FdycjL69++PDh068EwsIiIi0m3YcXNzw++//45Ro0Zh8uTJcHBwwJw5c9C5c2elz/Dhw/Hs2TP4+vriyZMnqFWrFgICAmBiYqL0Wb9+Pfr374+GDRtCT08Pbdu2xbx583SxSURERJTD6DTsAIC3tze8vb1fu1yj0WDy5MmYPHnya/sUKFAAGzZs+BjlERERUS6n85+LICIiIvqYGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1TIVdkqWLIlHjx5laH/y5AlKliz5wUURERERZZVMhZ1bt24hNTU1Q3tiYiLu37//wUURERERZRWD9+m8Y8cO5f/37t0LCwsL5X5qaioOHjwIe3v7LCuOiIiI6EO9V9hp3bo1AECj0aBbt25aywwNDWFvb4+ZM2dmWXFEREREH+q9wk5aWhoAwMHBAcHBwShUqNBHKYqIiIgoq7xX2El38+bNrK6DiIiI6KPIVNgBgIMHD+LgwYOIiopSRnzSrVy58oMLIyIiIsoKmQo7kyZNwuTJk+Hq6oqiRYtCo9FkdV1EREREWSJTYWfJkiXw8/NDly5dsroeIiIioiyVqevsJCUloUaNGlldCxEREVGWy1TY6dWrFzZs2JDVtRARERFluUwdxkpISMCyZctw4MABVKxYEYaGhlrLZ82alSXFEREREX2oTIWdixcvwsXFBQBw+fJlrWWcrExEREQ5SabCzuHDh7O6DiIiIqKPIlNzdoiIiIhyi0yN7NSvX/+Nh6sOHTqU6YKIiIiIslKmwk76fJ10ycnJOH/+PC5fvpzhB0KJiIiIdClTYWf27NmvbJ84cSLi4uI+qCAiIiKirJSlc3a++uor/i4WERER5ShZGnYCAwNhYmKSlaskIiIi+iCZOozVpk0brfsigocPH+LMmTMYN25clhRGRERElBUyFXYsLCy07uvp6aFcuXKYPHkyGjdunCWFEREREWWFTIWdVatWZXUdRERERB9FpsJOupCQEISGhgIAypcvj8qVK2dJUURERERZJVNhJyoqCh06dMCRI0dgaWkJAHjy5Anq16+P3377DYULF87KGomIiIgyLVNnYw0YMABPnz7FlStXEB0djejoaFy+fBmxsbEYOHBgVtdIRERElGmZGtkJCAjAgQMH4OjoqLQ5OTlh4cKFnKBMREREOUqmRnbS0tJgaGiYod3Q0BBpaWkfXBQRERFRVslU2GnQoAEGDRqEBw8eKG3379/HkCFD0LBhwywrjoiIiOhDZSrsLFiwALGxsbC3t0epUqVQqlQpODg4IDY2FvPnz8/qGomIiIgyLVNzdmxtbXH27FkcOHAAYWFhAABHR0d4enpmaXFEREREH+q9RnYOHToEJycnxMbGQqPRoFGjRhgwYAAGDBgANzc3lC9fHsePH/9YtRIRERG9t/cKO3PmzIGPjw/Mzc0zLLOwsEDv3r0xa9asLCuOiIiI6EO9V9i5cOECmjRp8trljRs3RkhIyAcXRURERJRV3ivsREZGvvKU83QGBgb4559/PrgoIiIioqzyXmGnWLFiuHz58muXX7x4EUWLFv3gooiIiIiyynuFnWbNmmHcuHFISEjIsCw+Ph4TJkyAt7d3lhVHRERE9KHe69TzsWPHYtu2bShbtiz69++PcuXKAQDCwsKwcOFCpKamYsyYMR+lUCIiIqLMeK+wY2VlhVOnTqFv374YNWoURAQAoNFo4OXlhYULF8LKyuqjFEpERESUGe99UUE7Ozvs3r0bjx8/xvXr1yEiKFOmDPLnz/8x6iMiIiL6IJm6gjIA5M+fH25ubllZCxEREVGWy9RvYxERERHlFjkm7Pz444/QaDQYPHiw0paQkIB+/fqhYMGCyJcvH9q2bYvIyEitx925cwfNmzdHnjx5UKRIEQwbNgwpKSnZXD0RERHlVDki7AQHB2Pp0qWoWLGiVvuQIUPwxx9/YPPmzTh69CgePHiANm3aKMtTU1PRvHlzJCUl4dSpU1i9ejX8/Pwwfvz47N4EIiIiyqF0Hnbi4uLQuXNnLF++XGuSc0xMDFasWIFZs2ahQYMGqFq1KlatWoVTp07hzz//BADs27cPf/31F9atWwcXFxc0bdoU33//PRYuXIikpKTXPmdiYiJiY2O1bkRERKROOg87/fr1Q/PmzeHp6anVHhISguTkZK32zz77DCVKlEBgYCAAIDAwEM7Ozlqnu3t5eSE2NhZXrlx57XNOmzYNFhYWys3W1jaLt4qIiIhyCp2Gnd9++w1nz57FtGnTMiyLiIiAkZERLC0ttdqtrKwQERGh9PnvdX3S76f3eZVRo0YhJiZGud29e/cDt4SIiIhyqkyfev6h7t69i0GDBmH//v0wMTHJ1uc2NjaGsbFxtj4nERER6YbORnZCQkIQFRWFKlWqwMDAAAYGBjh69CjmzZsHAwMDWFlZISkpCU+ePNF6XGRkJKytrQEA1tbWGc7OSr+f3oeIiIg+bToLOw0bNsSlS5dw/vx55ebq6orOnTsr/29oaIiDBw8qjwkPD8edO3fg4eEBAPDw8MClS5cQFRWl9Nm/fz/Mzc3h5OSU7dtEREREOY/ODmOZmZmhQoUKWm158+ZFwYIFlfaePXti6NChKFCgAMzNzTFgwAB4eHigevXqAIDGjRvDyckJXbp0wYwZMxAREYGxY8eiX79+PExFREREAHQYdt7F7Nmzoaenh7Zt2yIxMRFeXl5YtGiRslxfXx87d+5E37594eHhgbx586Jbt26YPHmyDqsmIiKinCRHhZ0jR45o3TcxMcHChQuxcOHC1z4m/YdJiYiIiF5F59fZISIiIvqYGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVdBp2pk2bBjc3N5iZmaFIkSJo3bo1wsPDtfokJCSgX79+KFiwIPLly4e2bdsiMjJSq8+dO3fQvHlz5MmTB0WKFMGwYcOQkpKSnZtCREREOZROw87Ro0fRr18//Pnnn9i/fz+Sk5PRuHFjPHv2TOkzZMgQ/PHHH9i8eTOOHj2KBw8eoE2bNsry1NRUNG/eHElJSTh16hRWr14NPz8/jB8/XhebRERERDmMgS6fPCAgQOu+n58fihQpgpCQENSpUwcxMTFYsWIFNmzYgAYNGgAAVq1aBUdHR/z555+oXr069u3bh7/++gsHDhyAlZUVXFxc8P3332PEiBGYOHEijIyMdLFpRERElEPkqDk7MTExAIACBQoAAEJCQpCcnAxPT0+lz2effYYSJUogMDAQABAYGAhnZ2dYWVkpfby8vBAbG4srV6688nkSExMRGxurdSMiIiJ1yjFhJy0tDYMHD0bNmjVRoUIFAEBERASMjIxgaWmp1dfKygoRERFKn5eDTvry9GWvMm3aNFhYWCg3W1vbLN4aIiIiyilyTNjp168fLl++jN9+++2jP9eoUaMQExOj3O7evfvRn5OIiIh0Q6dzdtL1798fO3fuxLFjx1C8eHGl3draGklJSXjy5InW6E5kZCSsra2VPqdPn9ZaX/rZWul9/svY2BjGxsZZvBVERESUE+l0ZEdE0L9/f/z+++84dOgQHBwctJZXrVoVhoaGOHjwoNIWHh6OO3fuwMPDAwDg4eGBS5cuISoqSumzf/9+mJubw8nJKXs2hIiIiHIsnY7s9OvXDxs2bIC/vz/MzMyUOTYWFhYwNTWFhYUFevbsiaFDh6JAgQIwNzfHgAED4OHhgerVqwMAGjduDCcnJ3Tp0gUzZsxAREQExo4di379+nH0hoiIiHQbdhYvXgwAqFevnlb7qlWr0L17dwDA7Nmzoaenh7Zt2yIxMRFeXl5YtGiR0ldfXx87d+5E37594eHhgbx586Jbt26YPHlydm0GERER5WA6DTsi8tY+JiYmWLhwIRYuXPjaPnZ2dti9e3dWlkZEREQqkWPOxiIiIiL6GBh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1VQTdhYuXAh7e3uYmJjA3d0dp0+f1nVJRERElAOoIuxs3LgRQ4cOxYQJE3D27FlUqlQJXl5eiIqK0nVpREREpGOqCDuzZs2Cj48PevToAScnJyxZsgR58uTBypUrdV0aERER6ZiBrgv4UElJSQgJCcGoUaOUNj09PXh6eiIwMPCVj0lMTERiYqJyPyYmBgAQGxub5fWlJT7P8nWqVVbuf+73d8f9rhvc77rB/a4bH+P79eX1isgb++X6sPPvv/8iNTUVVlZWWu1WVlYICwt75WOmTZuGSZMmZWi3tbX9KDXSu7GYo+sKPk3c77rB/a4b3O+68bH3+9OnT2FhYfHa5bk+7GTGqFGjMHToUOV+WloaoqOjUbBgQWg0Gh1Wlj1iY2Nha2uLu3fvwtzcXNflfDK433WD+103uN9141Pb7yKCp0+fwsbG5o39cn3YKVSoEPT19REZGanVHhkZCWtr61c+xtjYGMbGxlptlpaWH6vEHMvc3PyTeDPkNNzvusH9rhvc77rxKe33N43opMv1E5SNjIxQtWpVHDx4UGlLS0vDwYMH4eHhocPKiIiIKCfI9SM7ADB06FB069YNrq6uqFatGubMmYNnz56hR48eui6NiIiIdEwVYefLL7/EP//8g/HjxyMiIgIuLi4ICAjIMGmZXjA2NsaECRMyHMqjj4v7XTe433WD+103uN9fTSNvO1+LiIiIKBfL9XN2iIiIiN6EYYeIiIhUjWGHiIiIVI1hh4iIiFSNYYeIiIhUjWGHiIiIVI1hhygHSEtL03UJnyTu99yNV06hd8WwQ5QD6Om9eCv+/fffAPglnB3S0tKU/b569Wrs3btXxxXRm6QHm7Nnz2LPnj0A8En8cPPHEBMTo+sSsh3DDmVK+gdPeHg4Dhw4gAcPHiA1NVXHVeVue/bsQZkyZfDgwQPlS5g+DhFR9vGIESMwYcIEBAUFITo6mqMFOZCIQKPRYNu2bWjRogVOnz6N69evay2ndxMQEIDvvvsOx48f13Up2YqfqJQpGo0GW7duRY0aNdCjRw84Oztj7ty5ePDgga5Ly7WqVKkCDw8P+Pv7A+DozseUPiLw008/YeXKldi6dSvGjx+PAgUKcLQgB9JoNNi/fz+6du2KcePGYfTo0ShdurTWcgaet9u6dSvatGmD0qVLw9LSEsD/gqLa9x9/LoLeS/pfWDdu3EDnzp3RpUsXtGzZEosWLcLWrVvRvn179OnTB8WKFdN1qTnay4dQ0okIunfvjhs3bnxyf3XpQlxcHLp164ZGjRqhT58+uHHjBi5evIglS5agbNmy+Oabb/DZZ5/pukz6f126dIGlpSXmz5+P2NhYXLt2DVu2bEFSUhJ++OEHmJqaKp9PlNGlS5fQrFkzTJo0CV9//bXSfu3aNZQpUwYAVL3/VPFDoJR9NBoNAgMDcfjwYTg6OqJnz54wNjbG1KlTkTdvXqxduxYAGHjeIj3o3LlzBzY2NjAwMIBGo8HUqVNRtWpVLFu2DL6+vjquUt3y5cuHmJgYrFu3Dra2tpg/fz4SEhLg4OCADRs2ICYmBqtXr9Z1mZ+s9C/eU6dOoVixYihcuDBCQkIQFBSEJUuW4P79+3j06BFiYmIQHByMY8eOqfaLOis8fPgQZmZm6NKlC5KTk7FmzRqsX78eoaGhqFOnDjZu3Kjq/cfDWPTeVq9ejbFjxyIwMFBrotuYMWPQpUsXbN++HTNnzuQhrbfw8/NDw4YN0aFDB1y5cgUxMTEoVqwYvL29cfr0aQDqH1rOLq87JDh+/HgkJSWhS5cuqFatGqZMmYJVq1ZhwoQJePToERITE7O5UkqXfuiqefPmuHjxIipVqgRjY2PUrl0b8fHx+OabbxAUFIQJEyYgLS0Nz54903XJOVr6YavOnTvD3d0dO3bsgJOTE5YsWYLNmzdj48aNui3wI+PIDr23JUuWIH/+/Fi+fDnWrVuH7t27o0CBAgBeBJ7nz5/jwIEDGDVqlI4rzVlePnSVkpKCL774AikpKdi5cycaNGgAT09PdO3aFW3btkWrVq3Qp08fuLq66rjq3O/lyci//PILzp49iyJFiqBKlSpo2bIlTp8+jTt37qBEiRLKY/z9/VG6dGkYGxvrquxPXmRkJHbs2IExY8agRYsWAIDGjRsjIiIClStXVvqdPn0a+fLl46T+V/j333+RlJSEvHnzolq1ahg5ciT27NmDxo0bo2vXrnBycsLz589Rs2ZNFCxYUNflflxC9AZpaWkiIvLo0SOJjo6W6OhoZVnfvn2lZMmSMn/+fHn8+LHW4/7999/sLDPHS01NVf7/559/lrFjx8qdO3eUts2bN8uQIUPE1NRUOnXqJPr6+tKzZ0+Jj49X/g3o/b2878aMGSNmZmbSunVr8fDwkIIFC8rAgQOV5TExMbJnzx5p0qSJODs7S1JSUoZ1UPY4c+aMVKlSRZycnOT3339/ZZ+//vpLhgwZIpaWlnLx4sXsLTAX2L59u9SuXVtKlCghXl5eMmbMmFf2Gz9+vNjZ2cnt27ezucLsxbBDr5X+Ib99+3apU6eO2NnZiZeXl0yaNEnp06dPHylZsqQsWrRIHj16pKtSc41hw4ZJ4cKFZc2aNfLgwYMMy8PCwmTkyJHi5uYmRYoUUfYpv3DfX0pKivL/p0+flpYtW8qxY8dERCQ6OlpWr14tefLkkZEjR4qIyMmTJ8XX11datWolycnJIiLKfyl7paamSvPmzUWj0cjIkSMlMTFRRP73Pjh58qT4+PhI1apV5fz587osNUfas2ePmJiYyNy5c+X8+fMyceJE0Wg0sn37dqXPjh07xMfHRwoXLixnz57VYbXZg2GH3mjPnj1ibGws06dPl4ULF8qoUaPEzMxMfH19lT79+/cXS0tLWb58udYIBmlbs2aNFC1aVOuv0GfPnsmtW7e0+qWkpMizZ8/ExcVFa+SB3s2qVau07q9evVo8PT3Fzc1N/vnnH6U9Pj5e5s+fL+XKlZOwsDBJSEiQ69evK69hBp3s86own5qaKp9//rmULVtWNmzYIAkJCVrLg4KCJCIiIrtKzDUSExOlZ8+eMnHiRBERiYqKkuLFi8uAAQO0+q1cuVL69u0rf/31ly7KzHacs0OKhIQEmJiYKPdTUlKwadMm+Pr6Yvjw4UqfypUro1evXihZsiRGjBiB+fPnw9TUFPXq1eNx8/9Xu3ZtdO3aFT4+PkpbZGQkqlatCmdnZ1y7dg0BAQGYP38+LCwsUKtWLcyePRvAizO18uTJg+bNm+PGjRu62oRcae7cuQgODkbXrl2V16K+vj4ePHiAv//+G2fOnEGTJk0AACYmJqhZsybGjh2Lu3fvoly5cihVqhSAF/OrDAz48Zgd5P/PugoMDMTRo0eRkJCA8uXL44svvsCWLVvQunVrTJ8+HXp6emjdurUyj6patWo6rjxnMjIywo0bN+Dh4YGHDx/Czc0NzZo1w7x58wAAmzZtgpWVFXr06IEOHTrA1NRUxxVnD34zEQBgxowZqFevXoazf8LCwvDkyRPlvomJCby9vdG9e3cEBQUpZ0DMmDFD6yJfn7KUlBQMHDgQXbt2zdAeHh4OHx8ffP755zh58iQ6dOiA1q1bY/fu3bh69SqA/13w7uHDh7h69Sri4+OzfRtyq86dO8PPzw96eno4duyY0jZz5kx89tlnWLRokdY1jNJPaX7+/LnWehjas8/LV0YODAzEnTt38OWXX2L48OHQ09PD9u3bYWdnh59++gm//fYbz5B7jeTkZAAvPmfKli2L4OBg1KxZE82aNcOyZcsAAE+ePMHevXtx7tw5pKamfjJBBwAnKNMLoaGhynDmy3MdfvjhB6lbt65cuHBBq/+0adOkQoUK8vz582ytM7f54YcfZMSIEcr9YcOGSdu2bWXp0qVy7do1ERE5deqUVK1aVetw1s2bN8Xb21vOnDmT7TXnRiNGjJCQkBDl/t69e6Vs2bIybtw4pW3btm3i5uYm1atXl/nz58vmzZvF29tbnJyctF7zlL3Cw8PF1tZWFi5cKCIi9+7dE1NTUxkyZIjy75Kamiq1a9eWWrVqSWxsrC7LzZH27Nkj3bt3l/v374uIyL59+0RPT08qVqyonDySlpYmo0ePFnt7e7l+/boOq9UNhp1P3MtfECIix48fFycnJ3ny5ImIvHjTVKhQQQYOHKg1EbB///7i7e0tz549y9Z6c5PU1FSZNWuWaDQa5fi5iGgFxGfPnom3t7d4eXlpzXdKS0uTp0+fZmu9udW5c+ekWrVq4uHhIVeuXBERkQcPHsiAAQOkRo0aMmHCBKWvv7+/VKhQQfT09KRFixYyduxY5QuVgSd7pc/TCQwMlFq1aonIi5BfrFgx6dOnj9Lv3LlzIvLi/fTyGYz0wpYtW8TCwkKGDh2qNdF47dq1oqenJ61bt5Z27dpJp06dxNLS8pOYjPwqDDufsFOnTolGo5EFCxYobZcvX5aSJUuKi4uLxMTEiIjIunXrxNnZWdzd3aVFixbyxRdfiJmZGc+C+I9XTbJ8/vy5LF26VPT19bUCT2xsrMydO1eaNm0qlSpVUk5z5gTvzAkICJDmzZuLu7u7MgoZEREhgwcPFnd3d63As3v3bnF1dRVfX18JDAwUEe53XUg/w+rYsWPi5OQkR48eFXt7e/H19VWC559//int2rWT8PBwXZaaY128eFEKFy4sy5Yt02pPn4h/8uRJ6d+/v3z++ecyYcIECQsL00WZOQLDziduypQpYmRkJIsWLVLa/vrrL6lUqZI4OTkpgefw4cMyd+5cadGihQwdOlT5C5peePnL8vHjx1rXHYqPj5dFixaJvr6+fP/990r7uHHjpF+/fjzN+QO8PBqze/duadq06WsDz8thc/PmzVKtWjXp3Lmzcjo6ZZ8zZ85I//79JSYmRh48eCANGzYUc3Nz6dSpk1a/YcOGiaenJ6/b9Rr+/v7i4eEhIi+uhebn5yeNGzcWGxsbGTlypCQlJfGyFf+PYYfkxx9/FD09PeWYuYjIlStXpFKlSlK+fHkl8Ii8GL3gm+d/0tLStILO9OnTpUaNGlK5cmVp2bKlcpgvKSlJFi1aJAYGBjJ58mStx4vwEEpW2blz5ysDz5AhQ8TDw0OGDh2q9P3jjz+kTJky0qtXL4mPj9dVyZ+kWbNmibOzs1y6dElERBYuXChWVlYyYMAACQoKkvPnz8u3337LCwa+wsufvydPnhSNRiMjRowQV1dXadmypQwaNEimT58uhoaGcurUKR1WmrMw7HzCXn7TTJ069bWBx8XFJcMVkimj0aNHi7W1tSxcuFD27dsnVlZW0qBBA7l69aqIvAg8S5YsEY1GIytWrFAex/D4YaZNmyb9+vVT7r8u8PTo0UN8fHy0RtB2794tN27cyPaaPzXpr/GX56vVrFlT6tatq9z/8ccfpVatWmJkZCSVK1eWypUrK/N16H/S/4BKD+hLly6VGjVqyJAhQ7SCoZubm+zdu1cnNeZEDDufoPQPnv9+yX7//fcZAs9ff/0lJUqUkJo1a/JL+SVjxoyR+fPnK/f37Nkjzs7OyiGR3bt3i5mZmVhZWUn58uWVM68SExNl27ZtPGSVRZKTk2XOnDmi0Whk1KhRSnt64KlevbryBfDo0SNeMFCHAgICpGvXrrJ//34REblx44aULFlS64rsDx8+lODgYLlx4wavyP4Ku3fvltatW0u9evWkffv2ymv7v2fFjho1ShwcHOTevXu6KDNHYtj5xKQHliNHjsiYMWPEx8dHFixYoPy1MGXKlAyBJywsTP7++2+d1JsTPX78WOrVqyd16tSRlStXisiLyd4//fSTiLz4UC9YsKAsWbJEbt26JYULF5aGDRtmuFIpv3DfX3pYeTl4x8XFybJly8TAwECGDx+utO/cuVO8vb2lZMmSWqfacjJy9ktLS5Ovv/5aNBqNFCxYUCZPniw3btyQH374Qdq3by/BwcFKP3o1f39/MTIykpEjR8rAgQOlWbNmYmxsLP7+/iLyYt/5+/tL165dP5mfgHgfDDufoK1bt0q+fPmkb9++0r17d6lcubJ4eHgoZwT9+OOPYmxsLD///LOOK8150j+MIyMjpV27dlK/fn3x8/MTkRc/fhoXFyf169dXru8SHR0tbm5uotFoMky+pPfzckgJCgrSWvbs2TNZsmSJGBgYKL91JfLitNxvv/2Wc6J04L/BJTAwUDp27Cjff/+9VKlSRfr27Su9evUSR0dHmTdv3isfQy8kJSVJ06ZNtV7bz58/lyFDhoiJiYlywsivv/4qnTp14gkkr8Cw8wl4+Uvi9u3b4uTkpIzc3Lx5UwoVKqQ150HkxWGaggULav3KOWlPJD516pTUrVtXqlWrJuvXrxeRF+HGwcFBdu7cKSIiT58+la5du0poaChHFD7Ay1+CISEhotFoZM6cOVp9nj59KtOnTxeNRiM//vhjhnUw8GS/gwcPKqOfqamp8s0334iPj4/ExMTIggULpGfPnqLRaESj0cjp06d1XG3OtH37dvnpp5/E0dFRFi9eLCL/OzEiLi5OGjVqpPxWYXx8PC/0+hoMOyq2cuVK5QMk/Yv23LlzUqZMGUlKSpLbt2+Lra2t1o967t+/Xxnh4emerzd06FBp1aqVVKtWTczMzKRcuXLi5+cnqampUqVKFaldu7asW7dO6tevL+7u7sr+5xfu+zt06JCsW7dORET69Okj3bp1k/Hjx0v+/PmVEYF0Z8+eFXNzc9FoNFpzqij7JSQkyPfffy8ajUa6d+8up06dkpSUFKlUqZJMmTJFRESePHkiffv2FRsbG2VeG/3PmTNnpECBArJp0yZp1aqV1oVc0/8A+Oqrr6RVq1Y6rDJ3YNhRqZs3b0qdOnXExcVF64yG8PBwadiwoRw5ckQJOulzRy5fviy9e/fmsd63WL16teTPn19CQkLk33//lfv370ujRo3Ezc1NNm7cqFzR19nZWRo1asQLBmZSWlqaxMbGSqNGjaRu3brSokULsbCwkPDwcPn3339l4sSJYmZmphV4bt68KT4+PrJ7927OicohTp8+LZ6enlKjRg0ZOnSo7N69W1q1aqVc0FFEOIL8CteuXZPx48crPzezZMkScXd3l8mTJ2tdKqF79+7So0cPXlPnLRh2VGzfvn3SokULcXV1VX4W4tGjR+Lo6CgajUZ69uyp1f/bb7+VGjVqSGRkpC7KzTXGjx8vNWvWlNTUVOXD5d69e+Lm5iZly5aVzZs3S3Jysjx69EhZzi/ezHv06JGUK1dONBqNTJs2TWm/f/++TJw4UUxNTWX48OHKRQXbtGnD/a4D6fv80qVL8vvvv0tAQIDy8w73798XPz8/cXZ2FjMzMylZsqSMHz9el+XmaDExMeLq6iqFCxeWwYMHi8iL1/J3330nbm5u0qBBA5k6dap069ZN8uXLJ5cvX9ZxxTkfw44KvXyo5I8//pB27dqJm5ubcppiaGioFCxYUFq1aiW7du2SQ4cOyaBBg8Tc3DzDD37S/6R/mE+bNk1cXV2VY+PpIzf79++XvHnzipOTkzJnR4QjOh/q8ePH0qxZM6lTp440atRI1q5dqyx7+PChLFu2TCwtLaV8+fJSs2ZN5d+Df+Vmv82bN4uVlZWULl1a7O3txdLSUnbv3i0iL/49EhISZODAgaKvry9WVlb8/bc3OHv2rJQpU0ZcXFyUP1ZTUlJk9erV0qlTJ6lWrZq0bduWF118Rww7KpT+IR8QECCdO3eW6tWri0ajETc3N+UUzz///FPKly8vDg4OUq5cOalduzZ/6+odXb58WQwMDLR+fkBEZNeuXdKyZUsZPXo0A85H8PDhQ2nWrJnUr19fK/CIvBg5uH37Nq+jo0MhISFiYWEhy5cvl8jISAkNDZW+ffuKiYmJ7Nu3T6vv3r175ebNm7opNBe5cOGCVKxYUXr16pXhD9Hnz58rwZ7ejmFHpY4cOaJM0gwMDJR58+ZJrVq1tA5pxcTEyN9//y137tzR+kkIertVq1aJoaGhfPfdd3L69Gm5fv26NGvWTOvUUE5Gzno3btyQ5s2bS6NGjWTlypWSkpIiderUkdGjRyt9GDQ/voCAAElISNBq27x5s7i7uysTaEVe/Fv4+vqKtbU1D49n0tmzZ6VKlSrSq1cvHq76AAw7KpM+qjN69Gjx9vbWWrZr1y6pXr26uLm5Kb9JQ5m3ZcsWKVKkiBQvXlyKFy8ulStX5iGUbHDjxg1p06aNODo6SsmSJaVChQrKL2jTx3f37l3RaDTSr18/rf2+cuVKMTExUf5wSg/7wcHBYmtrqzUhmd7P2bNnpVq1atKhQwcJDQ3VdTm5kh5IVTQaDQDA0NAQN27cwNOnT5VlzZo1Q5s2bXDmzBl8/vnnuHDhgq7KVIW2bdvi3Llz2LZtG9auXYvg4GAYGhoiJSVF+XegrOfg4IAFCxZgxowZGD16NM6dOwcjIyOkpKToujTVGzt2LIKCgrB9+3asWrUKw4YNQ2JiIgCgQYMGcHJywuTJkxEdHQ19fX0AQOHChWFkZKT0o/dXuXJlLFiwAA8fPoSFhYWuy8mVDHRdAH0c5cuXx8aNG7F//340a9YMJiYmAAAXFxfUqFEDjo6OMDc313GVuZ+NjQ1sbGyU+6mpqTAw4NvqYytatCi8vb2V+9zvH9/06dOxePFinDp1CuXKlcPGjRvxxRdfAABmzpyJEiVKoEWLFjhw4AAmT56M0aNHQ6PRYPny5UhLS0PZsmV1vAW5m5ubGwICApTPcno//HTI5UQEGo0GFy9eRExMDACgdu3a+OKLL7Bu3TqMGDECqampaNCgAQoWLIhDhw7hs88+w08//QRLS0vdFq9C6X/NUvbifv+4UlJScObMGXTo0AHlypXD6dOnUbp0aWzevBlt27ZFWloa5s+fj/Hjx0NfXx87duxA0aJFUalSJURERGDnzp0oWrSorjcj12PQyTyNiIiui6APs3XrVnz99dcoVKgQHj58iL59+2LmzJkAgDZt2iA8PBzPnj1DiRIlEBwcjODgYFSoUEHHVRNRbpGUlISBAwfi1q1bcHV1xc8//4xDhw6hRo0a8Pf3R/v27eHj44MFCxZARPDvv//i2LFjsLS0RNmyZWFra6vrTaBPHMNOLpU+ovP06VPUr18fAwcORNWqVXH+/Hn4+PigY8eOWLFiBQAgICAAoaGhSElJQatWrTicTETvLSYmBq6urrh37x769OmD2bNnK8vSA4+vry9mzZoFQ0NDHVZKlBEPY+VSGo0Ge/fuxZ49e1C1alW0atUKFhYWKF++PCwsLNChQwdoNBr88ssvaNKkCZo0aaLrkokol0pJScHjx4/x999/w97eHrdu3cK+ffvQuHFjAECrVq2wadMmdO7cGfHx8Vi0aBGMjIx0XDXR//BsrFzs5s2bmDdvHvbt26dMzhQReHt7Y+PGjdi6dSs6deqk4yqJKLczMDCAvb09QkNDceDAAdy7dw/z58/H/v37lT6tWrXCypUrsXPnTjx+/FiH1RJlxMNYuUz64SsAiIuLw5YtW+Dr64tRo0Zh0qRJWn23bduGgQMH4syZM7C2ttZFuUSUS6V/1ty+fRv//PMPXFxcALwIPmfPnkWfPn1gZWWFgQMHolGjRsrj4uLikC9fPh1VTfRqDDu5RPoHT0JCAoyMjKCn92JQ7vnz51izZg369++PCRMmYNy4cVqPe/bsGfLmzauLkokol9u6dSuGDBmCxMRE2NjYYPjw4WjevDnMzc1x7tw59O7dGzY2NvDx8UHz5s11XS7RazHs5ALpQWffvn1YvHgx4uPjUahQIfj5+cHAwADJycn45ZdfMGDAAOX6FkREmZH+eRMWFoa2bdvCx8cHNWrUwNSpU3H79m306tULXbp0gbm5Oc6fP4/27dujSpUqWLlyJfLkyaPr8oleiWEnh0tNTYW+vj62b9+Obt26oUePHnB0dMSMGTNgZ2eHpUuXokyZMkhOTsbKlSvRt29fzJgxA999952uSyeiXOrs2bM4cuQIbt++jblz5yrtPXr0wPnz57UCz6VLl5AvXz44ODjosGKiN2PYyYHWrl2Lp0+f4ptvvgEAXLlyBV9++SX69OmD/v374+HDh3B3d8ejR4/g4OCA7du3o3Tp0khKSsK6devg4eEBR0dHHW8FEeU2aWlpAICGDRvi6NGjqF27Ng4fPqwcNgdeBJ7Lly/jyy+/RO/evWFmZqarconeGc/GymGePXuGNWvWYN26dfDz8wMAJCcno2XLlujfvz/u37+PWrVqoVmzZrh06RJiY2PRu3dvhIWFwcjICF9//TWDDhG9l/S/eePi4qCnp4fdu3ejTZs2uHHjBjZu3IikpCSl76pVq2BnZ4c//viDv0dGuQZHdnKghw8fYtCgQYiKikL37t3RvXt33LhxA/b29ujSpQvS0tKwevVqaDQaNG/eHAcOHIC7uzuOHTvGi3kRUaacPn0aM2fOxJAhQ1C9enXEx8ejZcuWePLkCUaNGoUWLVpofb48ePBA63fhiHIyjuzkICKC5ORkFC1aFBMnTkSePHmwfPly/PrrryhZsiT09PRw48YN1KlTB0ZGRjA0NETZsmVx7NgxbNy4kUGHiDLt2rVruHr1KhYuXIgzZ87A1NQU/v7+sLCwwNSpU7Fr1y4kJycr/Rl0KDdh2MlhDA0NsWnTJkyaNAlPnjzB+fPnMX78eKxevRrAi2tc/Pbbbzh+/DiGDBmC33//HQ4ODihRooSOKyei3Kxz584YMWIEbt26hZkzZyI4OBh58uTBjh07UKhQIXz33XfYu3evrsskyhQexsphgoKC0KBBA8yfPx81a9aEvr4+fHx88Pz5c3z33XcoU6YMunTpgpiYGBgZGWHz5s2oXLmyrssmolwoLCwMxsbGWmdSbdiwAUuWLIGNjQ1GjhwJFxcXPHv2DF999RVmzZrFs64oV2LYyWGWLVuGuXPnKsPIAHD//n106NABkZGRmDp1Klq0aIGHDx/CzMwMBQsW1HHFRJQb3bt3D02bNkWNGjUwatQo2NvbK8vWrFmDwYMHo0mTJhg0aBDc3d11VyhRFuBhrBzG1NQUqampiIuLA/DiTKxixYph0aJFePjwISZOnIgtW7bA3t6eQYeI3kv637YXL16Eubk5vv76a5w7dw5z5szBzZs3lX5du3ZF+fLlcfDgQfzyyy9ISEgA/y6m3IxhJ4fx8PDA7du3MX/+fABQJh0nJSWhSpUqqFixImrXrq3LEokoF0q/MvL27dvRqFEjzJ07F0OGDEGHDh1w7NgxzJ07F7du3QIAJCQkwNHREYMGDcKECRNgYmKi/CYfUW5koOsCSFvp0qWxfPlyfP3110hNTYWPjw8sLS3h7+8PBwcHzJs3D+bm5rouk4hyGY1Gg127dqFTp06YN28evLy8AABDhw6FiYkJVq9ejYiICDRp0gRhYWE4efIkpk2bxhFkUgXO2cmBRAS//fYbfH19UbhwYejp6eHx48fYv38/qlSpouvyiCgXSkhIQNeuXVGmTBlMmTIFz58/x7179/DHH3/AxcUFx48fx6VLlxAUFIRChQph5cqV/Lwh1eDITg6k0WjQsWNHeHh44OLFi4iPj4e7u7vWBEIiovchIrh58yasra0RHR2NCRMm4NKlS7h69Sr09fUxcOBArFixAk+fPkWePHk4okOqwpEdIqJPxJo1a9CnTx8YGhqiYcOGaN26Nbp27YpBgwbh8uXL2Lt3LwwM+DcwqQ9f1UREn4iuXbvC1dUV9+/fR6NGjZQf/kxNTUXx4sWRmprKsEOqxJEdIqJPVFhYGNauXYuFCxfixIkTqFChgq5LIvooGOGJiD5BISEhmDlzJs6fP4+jR48y6JCqcWSHiOgTFB8fjzNnzsDe3h62tra6Lofoo2LYISIiIlXjFZSJiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iIiISNUYdoiIiEjVGHaIiIhI1Rh2iEhRr149DB48WNdlfPLs7e0xZ84cXZdBpBoMO0SfkO7du0Oj0WS4Xb9+XdelvTcRwbJly+Du7o58+fLB0tISrq6umDNnDp4/f/7O69FoNNi+ffvHKzQTgoOD4evrq+syiFSDYYfoE9OkSRM8fPhQ6+bg4KDrsl4pKSnptcu6dOmCwYMHo1WrVjh8+DDOnz+PcePGwd/fH/v27cvGKrNO+vYWLlwYefLk0XE1ROrBsEP0iTE2Noa1tbXWTV9f/5V9Hz9+jK5duyJ//vzIkycPmjZtimvXrgF4MbJSuHBhbNmyRenv4uKCokWLKvdPnDgBY2NjZaTlyZMn6NWrFwoXLgxzc3M0aNAAFy5cUPpPnDgRLi4u+OWXX+Dg4AATE5NX1rVp0yasX78ev/76K0aPHg03NzfY29ujVatWOHToEOrXrw/gxQhJo0aNUKhQIVhYWKBu3bo4e/assh57e3sAwOeffw6NRqPcBwB/f39UqVIFJiYmKFmyJCZNmoSUlBRleVhYGGrVqgUTExM4OTnhwIEDGUaJLl26hAYNGsDU1BQFCxaEr68v4uLilOXdu3dH69atMWXKFNjY2KBcuXJKXS8fxnrbfrtw4QLq168PMzMzmJubo2rVqjhz5swr9x3Rp4hhh4heq3v37jhz5gx27NiBwMBAiAiaNWuG5ORkaDQa1KlTB0eOHAHwIhiFhoYiPj4eYWFhAICjR4/Czc1NGaX44osvEBUVhT179iAkJARVqlRBw4YNER0drTzn9evXsXXrVmzbtg3nz59/ZV3r169HuXLl0KpVqwzLNBoNLCwsAABPnz5Ft27dcOLECfz5558oU6YMmjVrhqdPnwJ4EYYAYNWqVXj48KFy//jx4+jatSsGDRqEv/76C0uXLoWfnx+mTJkCAEhNTUXr1q2RJ08eBAUFYdmyZRgzZoxWHc+ePYOXlxfy58+P4OBgbN68GQcOHED//v21+h08eBDh4eHYv38/du7c+crtfdt+69y5M4oXL47g4GCEhIRg5MiRMDQ0fOW6iD5JQkSfjG7duom+vr7kzZtXubVr105ZXrduXRk0aJCIiFy9elUAyMmTJ5Xl//77r5iamsqmTZtERGTevHlSvnx5ERHZvn27uLu7S6tWrWTx4sUiIuLp6SmjR48WEZHjx4+Lubm5JCQkaNVUqlQpWbp0qYiITJgwQQwNDSUqKuqN2+Ho6CgtW7Z87+1PTU0VMzMz+eOPP5Q2APL7779r9WvYsKFMnTpVq23t2rVStGhRERHZs2ePGBgYyMOHD5Xl+/fv11rXsmXLJH/+/BIXF6f02bVrl+jp6UlERISIvPj3sLKyksTERK3nsrOzk9mzZ4vIu+03MzMz8fPze8+9QfTpMNBx1iKibFa/fn0sXrxYuZ83b95X9gsNDYWBgQHc3d2VtoIFC6JcuXIIDQ0FANStWxeDBg3CP//8g6NHj6JevXqwtrbGkSNH0LNnT5w6dQrDhw8H8OJQS1xcHAoWLKj1PPHx8fj777+V+3Z2dihcuPAbt0FE3mlbIyMjMXbsWBw5cgRRUVFITU3F8+fPcefOnTc+7sKFCzh58qQykgO8GM1JSEjA8+fPER4eDltbW1hbWyvLq1WrprWO0NBQVKpUSWv/1qxZE2lpaQgPD4eVlRUAwNnZGUZGRm+s5W37bejQoejVqxfWrl0LT09PfPHFFyhVqtRb9g7Rp4Nhh+gTkzdvXpQuXTpL1uXs7IwCBQrg6NGjOHr0KKZMmQJra2tMnz4dwcHBSE5ORo0aNQAAcXFxKFq0qHLY62WWlpZa9b1N2bJllUNlb9KtWzc8evQIc+fOhZ2dHYyNjeHh4fHGic/ptU6aNAlt2rTJsOx184gy623b+y77beLEiejUqRN27dqFPXv2YMKECfjtt9/w+eefZ2mtRLkVww4RvZKjoyNSUlIQFBSkBJZHjx4hPDwcTk5OAF7Mj6lduzb8/f1x5coV1KpVC3ny5EFiYiKWLl0KV1dX5cu8SpUqiIiIgIGBgdZE4Mzo1KkTOnToAH9//wzzdkQEsbGxsLCwwMmTJ7Fo0SI0a9YMAHD37l38+++/Wv0NDQ2Rmpqq1ValShWEh4e/NhSWK1cOd+/eRWRkpDJCkz7fJ52joyP8/Pzw7NkzZR+cPHkSenp6ykTkd/Gu+61s2bIoW7YshgwZgo4dO2LVqlUMO0T/jxOUieiVypQpg1atWsHHxwcnTpzAhQsX8NVXX6FYsWJaAaNevXr49ddf4eLignz58kFPTw916tTB+vXrUbduXaWfp6cnPDw80Lp1a+zbtw+3bt3CqVOnMGbMmPc+c6h9+/b48ssv0bFjR0ydOhVnzpzB7du3sXPnTnh6euLw4cPKNqxduxahoaEICgpC586dYWpqqrUue3t7HDx4EBEREXj8+DEAYPz48VizZg0mTZqEK1euIDQ0FL/99hvGjh0LAGjUqBFKlSqFbt264eLFizh58qSyTKPRAHgxadjExATdunXD5cuXcfjwYQwYMABdunRRAtK7eNt+i4+PR//+/XHkyBHcvn0bJ0+eRHBwMBwdHd9rnxKpGcMOEb3WqlWrULVqVXh7e8PDwwMigt27d2ud6VO3bl2kpqaiXr16Slu9evUytGk0GuzevRt16tRBjx49ULZsWXTo0AG3b99+ry//9HVt2LABs2bNwvbt21G3bl1UrFgREydORKtWreDl5QUAWLFiBR4/fowqVaqgS5cuGDhwIIoUKaK1rpkzZ2L//v2wtbVF5cqVAQBeXl7YuXMn9u3bBzc3N1SvXh2zZ8+GnZ0dAEBfXx/bt29HXFwc3Nzc0KtXL+VsrPTDXHny5MHevXsRHR0NNzc3tGvXDg0bNsSCBQvee1vftN/09fXx6NEjdO3aFWXLlkX79u3RtGlTTJo06b2eh0jNNPKuM/2IiOi1Tp48iVq1auH69eucHEyUwzDsEBFlwu+//458+fKhTJkyuH79OgYNGoT8+fPjxIkTui6NiP6DE5SJiDLh6dOnGDFiBO7cuYNChQrB09MTM2fO1HVZRPQKHNkhIiIiVeMEZSIiIlI1hh0iIiJSNYYdIiIiUjWGHSIiIlI1hh0iIiJSNYYdIiIiUjWGHSIiIlI1hh0iIiJStf8DkrtR2qGbga8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#1. Size of the dataset\n",
        "\n",
        "dataset = tfds.load(dataset_name, split='train', data_dir=data_dir)\n",
        "size = tf.data.experimental.cardinality(dataset).numpy()\n",
        "print(f\"Size of the {dataset_name} dataset: {size}\")\n",
        "\n",
        "# Get information about the dataset\n",
        "info = tfds.builder(dataset_name).info\n",
        "\n",
        "print(info)\n",
        "\n",
        "#2. What type of data attributes are there?\n",
        "# Access the attributes\n",
        "num_classes = info.features['label'].num_classes\n",
        "class_names = info.features['label'].names\n",
        "splits = info.splits.keys()\n",
        "\n",
        "# Print the information\n",
        "print(\"Number of classes:\", num_classes)\n",
        "print(\"Class names:\", class_names)\n",
        "print(\"Splits:\", splits)\n",
        "\n",
        "#3. What are you classifying?\n",
        "# Print the class names\n",
        "print(\"The tf_flowers dataset is classifying the following classes:\")\n",
        "for class_name in class_names:\n",
        "    print(class_name)\n",
        "\n",
        "\n",
        "# 3. Classify the flowers\n",
        "category_count = [0] * num_classes\n",
        "for data in dataset:\n",
        "    label = data['label'].numpy()\n",
        "    category_count[label] += 1\n",
        "\n",
        "# 4. Plot the distribution of categories\n",
        "plt.bar(range(num_classes), category_count)\n",
        "plt.xticks(range(num_classes), class_names, rotation=45)\n",
        "plt.xlabel('Flower Categories')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Flower Categories')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Observations:\n",
        "\n",
        "#Size of the dataset: The size of the TensorFlow Flowers dataset is 3,670.\n",
        "\n",
        "#Data Attributes: Each data instance in the dataset consists of an image and a label.\n",
        "#                 The image attribute represents the image of a flower, while the label attribute represents the category or class of the flower.\n",
        "\n",
        "#Classification: The task is to classify the images of flowers into their respective categories or classes. There are a total of 102 different flower categories in the dataset.\n",
        "\n",
        "#Distribution of Categories: The code provided plots a bar graph showing the distribution of flower categories in the dataset. Each bar represents a category,\n",
        "#                            and the height of the bar represents the count or frequency of that category in the dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "KyYcvQZrWkn3"
      },
      "id": "KyYcvQZrWkn3"
    },
    {
      "cell_type": "code",
      "source": [
        "#Observations:\n",
        "\n",
        "#Size of the dataset: The size of the TensorFlow Flowers dataset is 3,670.\n",
        "\n",
        "#Data Attributes: Each data instance in the dataset consists of an image and a label.\n",
        "#                 The image attribute represents the image of a flower, while the label attribute represents the category or class of the flower.\n",
        "\n",
        "#Classification: The task is to classify the images of flowers into their respective categories or classes. There are a total of 102 different flower categories in the dataset.\n",
        "\n",
        "#Distribution of Categories: The code provided plots a bar graph showing the distribution of flower categories in the dataset. Each bar represents a category,\n",
        "#                            and the height of the bar represents the count or frequency of that category in the dataset."
      ],
      "metadata": {
        "id": "i-mgRplNhjjY"
      },
      "id": "i-mgRplNhjjY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "id": "60d80d2f",
      "metadata": {
        "id": "60d80d2f"
      },
      "source": [
        "--------------Type the answers below this line--------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "102e0e36",
      "metadata": {
        "id": "102e0e36"
      },
      "source": [
        "# 3. Data Preparation -- Score: 1 Mark\n",
        "\n",
        "Perform the data prepracessing that is required for the data that you have downloaded.\n",
        "\n",
        "\n",
        "This stage depends on the dataset that is used."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06fdebf8",
      "metadata": {
        "id": "06fdebf8"
      },
      "source": [
        "## 3.1 Apply pre-processing techiniques\n",
        "\n",
        "* to remove duplicate data\n",
        "* to impute or remove missing data\n",
        "* to remove data inconsistencies\n",
        "* Encode categorical data\n",
        "* Normalize the data\n",
        "* Feature Engineering\n",
        "* Stop word removal, lemmatiation, stemming, vectorization\n",
        "\n",
        "\n",
        "IF ANY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd3118eb",
      "metadata": {
        "id": "dd3118eb"
      },
      "outputs": [],
      "source": [
        "##---------Type the code below this line------------------##\n",
        "\n",
        "#The TensorFlow Flowers dataset consists of image data, so some of the pre-processing techniques mentioned (such as stop word removal, lemmatization, stemming, and vectorization)\n",
        "# are not applicable in this context. However, I can provide you with code examples for the remaining pre-processing techniques that are relevant to image data.\n",
        "# Here's how you can apply those techniques:\n",
        "\n",
        "#Remove Duplicate Data:\n",
        "#Duplicate data removal is not applicable for image datasets since each image represents a unique instance. Hence, there's no need for specific code for removing duplicate data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Impute or Remove Missing Data:\n",
        "#In the case of image datasets, missing data typically refers to missing images or incomplete files. You can check for and remove any instances where images are missing or corrupt. Here's an example code snippet:\n",
        "import os\n",
        "dataset_path ='/content/dataset/tf_flowers'\n",
        "# Get the list of image files in the dataset\n",
        "image_files = os.listdir(dataset_path)\n",
        "\n",
        "# Check if each image file exists and remove missing files\n",
        "for file_name in image_files:\n",
        "    file_path = os.path.join(dataset_path, file_name)\n",
        "    if not os.path.isfile(file_path):\n",
        "        print(f\"Removing missing file: {file_name}\")\n",
        "        os.remove(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "kh26rCBLmjIh",
        "outputId": "d039d977-0f9e-4f98-d767-ab550815ab40"
      },
      "id": "kh26rCBLmjIh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing missing file: downloads\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1ccebfb8e992>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Removing missing file: {file_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content/dataset/tf_flowers/downloads'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Remove Data Inconsistencies:\n",
        "#Data inconsistencies may arise if the dataset has mislabeled images or incorrect metadata. You can manually inspect and correct such inconsistencies. Here's an example code snippet for updating metadata:\n",
        "\n",
        "# Update label of a specific instance\n",
        "dataset = dataset.map(lambda x: {'image': x['image'], 'label': updated_label} if x['label'] == incorrect_label else x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "xsbqcIZml0G7",
        "outputId": "0c066668-41b9-4ab1-bb1d-c43d8896c164"
      },
      "id": "xsbqcIZml0G7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-2b2f7d421f5c>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Update label of a specific instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mupdated_label\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mincorrect_label\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2238\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmap_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2240\u001b[0;31m     return map_op._map_v2(\n\u001b[0m\u001b[1;32m   2241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2242\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     35\u001b[0m       warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[1;32m     36\u001b[0m                     \"`num_parallel_calls` argument is specified.\")\n\u001b[0;32m---> 37\u001b[0;31m     return _MapDataset(\n\u001b[0m\u001b[1;32m     38\u001b[0m         input_dataset, map_func, preserve_cardinality=True, name=name)\n\u001b[1;32m     39\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     self._map_func = structured_function.StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \"\"\"\n\u001b[0;32m--> 232\u001b[0;31m     concrete_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m    233\u001b[0m         *args, **kwargs)\n\u001b[1;32m    234\u001b[0m     \u001b[0mconcrete_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m       \u001b[0mconcrete_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0mconcrete_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arg_keywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_concrete_function_internal_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplaceholder_bound_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           concrete_function = self._create_concrete_function(\n\u001b[0m\u001b[1;32m    397\u001b[0m               args, kwargs, func_graph)\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     concrete_function = monomorphic_function.ConcreteFunction(\n\u001b[0;32m--> 300\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1212\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    236\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    167\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_variables_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filefqquyzp5.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtf__lam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_function_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mlscope\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mincorrect_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mupdated_label\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"x['label'] == incorrect_label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lscope'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf__lam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/core/function_wrappers.py\u001b[0m in \u001b[0;36mwith_function_scope\u001b[0;34m(thunk, scope_name, options)\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;34m\"\"\"Inline version of the FunctionScope context manager.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mFunctionScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lambda_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/__autograph_generated_filefqquyzp5.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(lscope)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtf__lam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_function_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mlscope\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mincorrect_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mupdated_label\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"x['label'] == incorrect_label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lscope'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf__lam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: in user code:\n\n    File \"<ipython-input-10-2b2f7d421f5c>\", line 5, in None  *\n        lambda x: {'image': x['image'], 'label': updated_label} if x['label'] == incorrect_label else x\n\n    NameError: name 'incorrect_label' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Encode Categorical Data:\n",
        "#Encoding categorical data is not necessary for image datasets, as the labels are typically stored as numerical values or string class names. However, if you have categorical metadata associated with each image (e.g., color, shape), you can encode them using one-hot encoding or label encoding. Here's an example code snippet for label encoding:\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Get the labels from the dataset\n",
        "labels = [data['label'] for data in dataset]\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the labels\n",
        "encoded_labels = label_encoder.fit_transform(labels)"
      ],
      "metadata": {
        "id": "R7zNdTrcmRaJ"
      },
      "id": "R7zNdTrcmRaJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Normalize the Data:\n",
        "#Image normalization is often performed to scale the pixel values between 0 and 1. Here's an example code snippet for normalizing the pixel values:\n",
        "\n",
        "# Normalize pixel values between 0 and 1\n",
        "dataset = dataset.map(lambda x: {'image': x['image'] / 255.0, 'label': x['label']})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "2Rk-4xuPm2mr",
        "outputId": "2ba5a044-d3cd-4367-9261-01f049e6630d"
      },
      "id": "2Rk-4xuPm2mr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-73c74069a0bd>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Normalize pixel values between 0 and 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2238\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmap_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2240\u001b[0;31m     return map_op._map_v2(\n\u001b[0m\u001b[1;32m   2241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2242\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     35\u001b[0m       warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[1;32m     36\u001b[0m                     \"`num_parallel_calls` argument is specified.\")\n\u001b[0;32m---> 37\u001b[0;31m     return _MapDataset(\n\u001b[0m\u001b[1;32m     38\u001b[0m         input_dataset, map_func, preserve_cardinality=True, name=name)\n\u001b[1;32m     39\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     self._map_func = structured_function.StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \"\"\"\n\u001b[0;32m--> 232\u001b[0;31m     concrete_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m    233\u001b[0m         *args, **kwargs)\n\u001b[1;32m    234\u001b[0m     \u001b[0mconcrete_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m       \u001b[0mconcrete_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0mconcrete_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arg_keywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_concrete_function_internal_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplaceholder_bound_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           concrete_function = self._create_concrete_function(\n\u001b[0m\u001b[1;32m    397\u001b[0m               args, kwargs, func_graph)\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     concrete_function = monomorphic_function.ConcreteFunction(\n\u001b[0;32m--> 300\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1212\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    236\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    167\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_variables_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file0jqzcvxv.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtf__lam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_function_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mlscope\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lscope'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf__lam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/core/function_wrappers.py\u001b[0m in \u001b[0;36mwith_function_scope\u001b[0;34m(thunk, scope_name, options)\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;34m\"\"\"Inline version of the FunctionScope context manager.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mFunctionScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lambda_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/__autograph_generated_file0jqzcvxv.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(lscope)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtf__lam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_function_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mlscope\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lscope'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf__lam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_truediv_python3\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1567\u001b[0m     \u001b[0my_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1569\u001b[0;31m       raise TypeError(f\"`x` and `y` must have the same dtype, \"\n\u001b[0m\u001b[1;32m   1570\u001b[0m                       f\"got {x_dtype!r} != {y_dtype!r}.\")\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"<ipython-input-20-73c74069a0bd>\", line 5, in None  *\n        lambda x: {'image': x['image'] / 255.0, 'label': x['label']}\n\n    TypeError: `x` and `y` must have the same dtype, got tf.uint8 != tf.float32.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6.Feature Engineering:\n",
        "#Feature engineering for image datasets typically involves techniques like data augmentation, cropping, or resizing. These techniques aim to enhance the model's performance by increasing the variety and quality of the training data. Here's an example code snippet using TensorFlow's data augmentation:\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "dataset = dataset.map(lambda x: {'image': data_augmentation(tf.expand_dims(x['image'], 0))[0], 'label': x['label']})"
      ],
      "metadata": {
        "id": "JOymxg1gydpN"
      },
      "id": "JOymxg1gydpN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "793cd04b",
      "metadata": {
        "id": "793cd04b"
      },
      "source": [
        "## 3.2 Identify the target variables.\n",
        "\n",
        "* Separate the data front the target such that the dataset is in the form of (X,y) or (Features, Label)\n",
        "\n",
        "* Discretize / Encode the target variable or perform one-hot encoding on the target or any other as and if required.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9089b57",
      "metadata": {
        "id": "c9089b57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ae39fd-d9ae-4293-f84a-5600aacc0389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (3670,)\n",
            "One-hot encoded labels shape: (3670, 5)\n",
            "Class names: [0 1 2 3 4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-d9e687b99978>:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  data = np.array([data['image'] for data in dataset])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "##---------Type the code below this line------------------##\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "# Load the dataset\n",
        "dataset, info = tfds.load('tf_flowers', split='train', with_info=True)\n",
        "\n",
        "# Get the labels from the dataset\n",
        "labels = np.array([data['label'] for data in dataset])\n",
        "\n",
        "# Identify the target variable\n",
        "target_variable = 'label'\n",
        "\n",
        "# Separate the data from the target\n",
        "data = np.array([data['image'] for data in dataset])\n",
        "\n",
        "# Perform one-hot encoding on the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Fit and transform the labels using label encoder\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Reshape the labels to match the input shape expected by onehot_encoder\n",
        "encoded_labels = encoded_labels.reshape(len(encoded_labels), 1)\n",
        "\n",
        "# Perform one-hot encoding on the encoded labels\n",
        "onehot_labels = onehot_encoder.fit_transform(encoded_labels)\n",
        "\n",
        "# Print the shape of data and one-hot encoded labels\n",
        "print(\"Data shape:\", data.shape)\n",
        "print(\"One-hot encoded labels shape:\", onehot_labels.shape)\n",
        "\n",
        "# Optionally, you can also retrieve the class names corresponding to the one-hot encoded labels\n",
        "class_names = label_encoder.classes_\n",
        "print(\"Class names:\", class_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#In the above code, the target variable is identified as the 'label'.\n",
        "#The dataset is then separated into 'data' (image features) and 'onehot_labels' (one-hot encoded labels).\n",
        "#The label encoding is performed using LabelEncoder, and then one-hot encoding is applied using OneHotEncoder.\n",
        "#The class names corresponding to the one-hot encoded labels can also be retrieved using label_encoder.classes_."
      ],
      "metadata": {
        "id": "20ehHcrO33ZE"
      },
      "id": "20ehHcrO33ZE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4cd14601",
      "metadata": {
        "id": "4cd14601"
      },
      "source": [
        "## 3.3 Split the data into training set and testing set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a74cd9c",
      "metadata": {
        "id": "1a74cd9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca9c2a2e-ded9-4029-a919-37cbd91ce7a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set - X shape: 2936\n",
            "Training set - y shape: 2936\n",
            "Testing set - X shape: 734\n",
            "Testing set - y shape: 734\n"
          ]
        }
      ],
      "source": [
        "##---------Type the code below this line------------------##\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Split the dataset into features (X) and labels (y)\n",
        "X = [data['image'] for data in dataset]\n",
        "y = [data['label'] for data in dataset]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the training and testing sets\n",
        "print(\"Training set - X shape:\", len(X_train))\n",
        "print(\"Training set - y shape:\", len(y_train))\n",
        "print(\"Testing set - X shape:\", len(X_test))\n",
        "print(\"Testing set - y shape:\", len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#In the above code, the TensorFlow Flowers dataset is loaded, and the features (X) and labels (y) are extracted from the dataset. The train_test_split function from scikit-learn is then used to split the data into training and testing sets. The test_size parameter determines the percentage of the dataset that will be allocated to the testing set (in this case, 20%). The random_state parameter ensures reproducibility of the split."
      ],
      "metadata": {
        "id": "5KV6XyB5DkG-"
      },
      "id": "5KV6XyB5DkG-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e3cec4fc",
      "metadata": {
        "id": "e3cec4fc"
      },
      "source": [
        "## 3.4 Preprocessing report\n",
        "\n",
        "Mention the method adopted  and justify why the method was used\n",
        "* to remove duplicate data, if present\n",
        "* to impute or remove missing data, if present\n",
        "* to remove data inconsistencies, if present\n",
        "* to encode categorical data\n",
        "* the normalization technique used\n",
        "\n",
        "If the any of the above are not present, then also add in the report below.\n",
        "\n",
        "Report the size of the training dataset and testing dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71c77697",
      "metadata": {
        "id": "71c77697"
      },
      "outputs": [],
      "source": [
        "##---------Type the answer below this line------------------##"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the first image from the dataset\n",
        "first_image = next(iter(dataset))['image']\n",
        "\n",
        "# Print the shape of the first image\n",
        "print(\"Input shape:\", first_image.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX_Qx_AeGGXt",
        "outputId": "2e3bae30-1c5b-4e85-b886-6053ae651831"
      },
      "id": "hX_Qx_AeGGXt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (333, 500, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ae0b5d2",
      "metadata": {
        "id": "3ae0b5d2"
      },
      "source": [
        "# 4. Deep Neural Network Architecture - Score:  Marks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "186bf4d7",
      "metadata": {
        "id": "186bf4d7"
      },
      "source": [
        "## 4.1 Design the architecture that you will be using\n",
        "\n",
        "* Sequential Model Building with Activation for each layer.\n",
        "* Add dense layers, specifying the number of units in each layer and the activation function used in the layer.\n",
        "* Use Relu Activation function in each hidden layer\n",
        "* Use Sigmoid / softmax Activation function in the output layer as required\n",
        "\n",
        "DO NOT USE CNN OR RNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "868d7b27",
      "metadata": {
        "id": "868d7b27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e53dd1fa-1cfd-4bfb-cd54-f5807c56a4ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 333, 500, 256)     1024      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 333, 500, 128)     32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 333, 500, 64)      8256      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 333, 500, 5)       325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,501\n",
            "Trainable params: 42,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "##---------Type the code below this line------------------##\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "# Define the number of classes in the dataset\n",
        "num_classes = 5\n",
        "input_shape = (333, 500, 3)\n",
        "# Create a sequential model\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "\n",
        "# Add dense layers with ReLU activation\n",
        "model.add(layers.Dense(256, activation='relu', input_shape=input_shape))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "# Add the output layer with softmax activation for multi-class classification\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "575f9e37",
      "metadata": {
        "id": "575f9e37"
      },
      "source": [
        "## 4.2 DNN Report\n",
        "\n",
        "Report the following and provide justification for the same.\n",
        "\n",
        "\n",
        "\n",
        "* Number of layers\n",
        "* Number of units in each layer\n",
        "* Total number of trainable parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ad56d90",
      "metadata": {
        "id": "6ad56d90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4993be70-2041-4d11-ac16-3dd645680746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Layers: 4\n",
            "Number of Units in Each Layer: [256, 128, 64, 5]\n",
            "Total Number of Trainable Parameters: 42501\n"
          ]
        }
      ],
      "source": [
        "##---------Type the answer below this line------------------##\n",
        "# Print the number of layers\n",
        "num_layers = len(model.layers)\n",
        "print(\"Number of Layers:\", num_layers)\n",
        "\n",
        "# Print the number of units in each layer\n",
        "num_units = [layer.units for layer in model.layers if isinstance(layer, layers.Dense)]\n",
        "print(\"Number of Units in Each Layer:\", num_units)\n",
        "\n",
        "# Print the total number of trainable parameters\n",
        "total_params = model.count_params()\n",
        "print(\"Total Number of Trainable Parameters:\", total_params)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Number of Layers:\n",
        "#The len(model.layers) function is used to count the number of layers in the model.\n",
        "\n",
        "#Number of Units in Each Layer:\n",
        "#A list comprehension is used to iterate over the model's layers and extract the number of units for each dense layer (layers.Dense). This information is stored in the num_units list.\n",
        "\n",
        "#Total Number of Trainable Parameters:\n",
        "#The model.count_params() function is used to calculate the total number of trainable parameters in the model."
      ],
      "metadata": {
        "id": "RrCLPWGIK6Ko"
      },
      "id": "RrCLPWGIK6Ko",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bdbc82a1",
      "metadata": {
        "id": "bdbc82a1"
      },
      "source": [
        "# 5. Training the model - Score: 1 Mark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca214eb3",
      "metadata": {
        "id": "ca214eb3"
      },
      "source": [
        "## 5.1 Configure the training\n",
        "\n",
        "Configure  the model for training, by using appropriate optimizers and regularizations\n",
        "\n",
        "Compile with categorical CE loss and metric accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a85e9754",
      "metadata": {
        "id": "a85e9754",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a14d5a34-df18-4654-97f4-055dc908306f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 333, 500, 256)     1024      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 333, 500, 128)     32896     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 333, 500, 64)      8256      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 333, 500, 5)       325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,501\n",
            "Trainable params: 42,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "##---------Type the code below this line------------------##\n",
        "input_shape = (333, 500, 3)\n",
        "# Create a sequential model\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "\n",
        "# Add dense layers with ReLU activation\n",
        "model.add(layers.Dense(256, activation='relu', input_shape=input_shape))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "# Add the output layer with softmax activation for multi-class classification\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Configure the model for training\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "#In the above code, the model architecture is defined as before. After that, the model is configured for training using the compile() function. The optimizer parameter is set to 'adam', which is a commonly used optimization algorithm. The loss parameter is set to 'categorical_crossentropy', which is appropriate for multi-class classification tasks. The metrics parameter is set to ['accuracy'], which computes the accuracy of the model during training and evaluation.\n",
        "\n",
        "#Finally, the model summary is printed using model.summary() to provide an overview of the model's configuration.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32fd60d8",
      "metadata": {
        "id": "32fd60d8"
      },
      "source": [
        "## 5.2 Train the model\n",
        "\n",
        "Train Model with cross validation, with total time taken shown for 20 epochs.\n",
        "\n",
        "Use SGD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8efaa227",
      "metadata": {
        "id": "8efaa227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "610a5164-516c-44a8-e9b8-6f19992e486b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-7032705196e0>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Convert the labels to multilabel indicator format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Perform cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0mclass_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0mclass_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0myt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0;31m# sort classes and reorder columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, y, class_mapping)\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m                     \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot iterate over a tensor with unknown shape.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot iterate over a scalar tensor.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m       raise TypeError(\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot iterate over a scalar tensor."
          ]
        }
      ],
      "source": [
        "##---------Type the code below this line------------------##\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Define the number of classes in the dataset\n",
        "num_classes = 5\n",
        "\n",
        "# Define the input shape of the images\n",
        "input_shape = (224, 224, 3)  # Example shape, adjust according to your data\n",
        "\n",
        "# Create a sequential model\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Add dense layers with ReLU activation\n",
        "model.add(layers.Dense(256, activation='relu', input_shape=input_shape))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "\n",
        "# Add the output layer with sigmoid activation for multilabel classification\n",
        "model.add(layers.Dense(num_classes, activation='sigmoid'))\n",
        "\n",
        "# Configure the model for training\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',  # Use binary cross-entropy for multilabel classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load the dataset\n",
        "dataset = tfds.load('tf_flowers', split='train')\n",
        "\n",
        "# Separate the features and labels from the dataset\n",
        "X = []\n",
        "y = []\n",
        "for data in dataset:\n",
        "    image = tf.image.resize(data['image'], input_shape[:2])\n",
        "    X.append(image)\n",
        "    y.append(data['label'])\n",
        "\n",
        "X = tf.stack(X)\n",
        "y = tf.stack(y)\n",
        "\n",
        "# Convert the labels to multilabel indicator format\n",
        "\n",
        "y = mlb.fit_transform(y)\n",
        "\n",
        "# Perform cross-validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "total_time = 0\n",
        "for train_index, val_index in skf.split(X, y):\n",
        "    # Split the data into training and validation sets\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, verbose=0)\n",
        "    end_time = time.time()\n",
        "    epoch_time = end_time - start_time\n",
        "    total_time += epoch_time\n",
        "\n",
        "# Print the total time taken for 20 epochs\n",
        "print(\"Total time taken for 20 epochs (cross-validation):\", total_time, \"seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19bd0c56",
      "metadata": {
        "id": "19bd0c56"
      },
      "source": [
        "Justify your choice of optimizers and regulizations used and the hyperparameters tuned\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b89d2981",
      "metadata": {
        "id": "b89d2981"
      },
      "outputs": [],
      "source": [
        "##---------Type the answers below this line------------------##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06f1173c",
      "metadata": {
        "id": "06f1173c"
      },
      "source": [
        "# 6. Test the model - 0.5 marks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7042235d",
      "metadata": {
        "id": "7042235d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "47a0a26d-2ee1-4280-bfa0-33d0b45250ea"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-da6569a2796b>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Evaluate the model on the validation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Print the validation loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'val_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "##---------Type the code below this line------------------##\n",
        "\n",
        "# Evaluate the model on the validation dataset\n",
        "loss, accuracy = model.evaluate(val_dataset)\n",
        "\n",
        "# Print the validation loss and accuracy\n",
        "print(\"Validation Loss:\", loss)\n",
        "print(\"Validation Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb57940c",
      "metadata": {
        "id": "eb57940c"
      },
      "source": [
        "# 7. Intermediate result  - Score: 1 mark\n",
        "\n",
        "1. Plot the training and validation accuracy history.\n",
        "2. Plot the training and validation loss history.\n",
        "3. Report the testing accuracy and loss.\n",
        "4. Show Confusion Matrix for testing dataset.\n",
        "5. Report values for preformance study metrics like accuracy, precision, recall, F1 Score.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55a03506",
      "metadata": {
        "id": "55a03506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "outputId": "8e99084c-f94b-4233-e171-6892a419bce0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-60663e663360>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;31m# Plot the training and validation accuracy history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_6\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "##---------Type the code below this line------------------##\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "dataset = tfds.load('tf_flowers', split='train')\n",
        "\n",
        "# Split the dataset into train and validation sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size)\n",
        "\n",
        "# Preprocess the datasets\n",
        "preprocess = lambda data: (tf.image.resize(data['image'], (224, 224)) / 255.0, data['label'])\n",
        "train_dataset = train_dataset.map(preprocess)\n",
        "val_dataset = val_dataset.map(preprocess)\n",
        "\n",
        "# Configure the model\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Train the model\n",
        "history = model.fit(train_dataset, epochs=20, validation_data=val_dataset)\n",
        "# Plot the training and validation accuracy history\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "plt.show()\n",
        "\n",
        "# Plot the training and validation loss history\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model on the testing dataset\n",
        "test_dataset = tfds.load('tf_flowers', split='test')\n",
        "test_dataset = test_dataset.map(preprocess)\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "\n",
        "# Print the testing accuracy and loss\n",
        "print(\"Testing Loss:\", test_loss)\n",
        "print(\"Testing Accuracy:\", test_accuracy)\n",
        "\n",
        "# Get the true labels and predictions for the testing dataset\n",
        "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "y_pred = model.predict_classes(np.concatenate([x for x, y in test_dataset], axis=0))\n",
        "\n",
        "# Create the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# Report the performance study metrics\n",
        "report = classification_report(y_true, y_pred, target_names=class_names)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8146c5b",
      "metadata": {
        "id": "c8146c5b"
      },
      "source": [
        "# 8. Model architecture - Score: 1 mark\n",
        "\n",
        "\n",
        "Modify the architecture designed in section 4.1\n",
        "\n",
        "1. by decreasing one layer\n",
        "2. by increasing one layer\n",
        "\n",
        "For example, if the architecture in 4.1 has 5 layers, then 8.1 should have 4 layers and 8.2 should have 6 layers.\n",
        "\n",
        "Plot the comparison of the training and validation accuracy of the three architecures (4.1, 8.1 and 8.2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b15e18d9",
      "metadata": {
        "id": "b15e18d9"
      },
      "outputs": [],
      "source": [
        "##---------Type the code below this line------------------##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8d38cb0",
      "metadata": {
        "id": "d8d38cb0"
      },
      "source": [
        "# 9. Regularisations - Score: 1 mark\n",
        "\n",
        "Modify the architecture designed in section 4.1\n",
        "\n",
        "1. Dropout of ratio 0.25\n",
        "2. Dropout of ratio 0.25 with L2 regulariser with factor 1e04.\n",
        "\n",
        "Plot the comparison of the training and validation accuracy of the three (4.1, 9.1 and 9.2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7497b710",
      "metadata": {
        "id": "7497b710"
      },
      "outputs": [],
      "source": [
        "##---------Type the code below this line------------------##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6529c4a9",
      "metadata": {
        "id": "6529c4a9"
      },
      "source": [
        "# 10. Optimisers -Score: 1 mark\n",
        "\n",
        "Modify the code written in section 5.2\n",
        "\n",
        "1. RMSProp with your choice of hyper parameters\n",
        "2. Adam with your choice of hyper parameters\n",
        "\n",
        "Plot the comparison of the training and validation accuracy of the three (5.2, 10.1 and 10.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bf06eb1",
      "metadata": {
        "id": "9bf06eb1"
      },
      "outputs": [],
      "source": [
        "##---------Type the code below this line------------------##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c7522aa",
      "metadata": {
        "id": "7c7522aa"
      },
      "source": [
        "# 11. Conclusion - Score: 1 mark\n",
        "\n",
        "Comparing the sections 4.1, 5.2, 8, 9, and 10, present your observations on which model or architecture or regualiser or optimiser perfomed better.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc51130d",
      "metadata": {
        "id": "bc51130d"
      },
      "outputs": [],
      "source": [
        "##---------Type the code below this line------------------##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RcDDQlfbZQ7E",
      "metadata": {
        "id": "RcDDQlfbZQ7E"
      },
      "source": [
        "### NOTE\n",
        "\n",
        "\n",
        "All Late Submissions will incur a <b>penalty of -2 marks </b>. So submit your assignments on time.\n",
        "\n",
        "Good Luck"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}